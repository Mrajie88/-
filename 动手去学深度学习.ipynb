{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动手去学习深度学习_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单实现线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真实参数 w,b\n",
    "w0 = torch.tensor([2.5,3])\n",
    "b0 = 1\n",
    "n_input = 2\n",
    "n_examples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build X and y\n",
    "X = torch.tensor(np.random.normal(0,1,(n_examples,n_input)))\n",
    "labels = X[:,0]*w0[0]+X[:,1]*w0[1]+b0\n",
    "labels = labels+torch.tensor(np.random.normal(0,0.01,labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data loader\n",
    "dataset = torch.utils.data.TensorDataset(X,labels)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "            dataset = dataset,\n",
    "            batch_size = 10,\n",
    "            shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = torch.nn.Sequential(\n",
    "    nn.Linear(n_input,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init\n",
    "from torch.nn import init\n",
    "\n",
    "init.normal_(linear_model[0].weight,mean = 0,std = 0.01)\n",
    "init.constant_(linear_model[0].bias,val = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0171, -0.0097]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in linear_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.8189,  0.1676, -3.2272, -5.5785, -4.2469,  1.2893,  5.3571,  3.6089,\n",
      "         0.4966,  1.9021])\n",
      "tensor([[ 5.8189],\n",
      "        [ 0.1676],\n",
      "        [-3.2272],\n",
      "        [-5.5785],\n",
      "        [-4.2469],\n",
      "        [ 1.2893],\n",
      "        [ 5.3571],\n",
      "        [ 3.6089],\n",
      "        [ 0.4966],\n",
      "        [ 1.9021]])\n",
      "epoch 1, loss: 0.000065\n",
      "tensor([ 1.3533,  0.6045,  0.9706,  5.0472, -2.1584,  0.0159, -0.9849,  7.5362,\n",
      "        -1.8615, -1.5185])\n",
      "tensor([[ 1.3533],\n",
      "        [ 0.6045],\n",
      "        [ 0.9706],\n",
      "        [ 5.0472],\n",
      "        [-2.1584],\n",
      "        [ 0.0159],\n",
      "        [-0.9849],\n",
      "        [ 7.5362],\n",
      "        [-1.8615],\n",
      "        [-1.5185]])\n",
      "epoch 2, loss: 0.000092\n",
      "tensor([-6.1374, -0.9583,  0.9985, -8.3147, -2.1810,  2.9151,  0.0398,  6.2411,\n",
      "         4.3393,  5.0756])\n",
      "tensor([[-6.1374],\n",
      "        [-0.9583],\n",
      "        [ 0.9985],\n",
      "        [-8.3147],\n",
      "        [-2.1810],\n",
      "        [ 2.9151],\n",
      "        [ 0.0398],\n",
      "        [ 6.2411],\n",
      "        [ 4.3393],\n",
      "        [ 5.0756]])\n",
      "epoch 3, loss: 0.000103\n",
      "tensor([ 3.8316,  4.7838, -1.6300, -0.8008,  3.3473, -5.5053,  5.9372,  6.1496,\n",
      "        -0.0389,  6.6515])\n",
      "tensor([[ 3.8316],\n",
      "        [ 4.7838],\n",
      "        [-1.6300],\n",
      "        [-0.8008],\n",
      "        [ 3.3473],\n",
      "        [-5.5053],\n",
      "        [ 5.9372],\n",
      "        [ 6.1496],\n",
      "        [-0.0389],\n",
      "        [ 6.6515]])\n",
      "epoch 4, loss: 0.000085\n",
      "tensor([-0.1883,  2.2323,  2.0366, -1.1391, -0.1064, -2.5861,  4.5725,  1.4209,\n",
      "         1.7542,  0.8942])\n",
      "tensor([[-0.1883],\n",
      "        [ 2.2323],\n",
      "        [ 2.0366],\n",
      "        [-1.1391],\n",
      "        [-0.1064],\n",
      "        [-2.5861],\n",
      "        [ 4.5725],\n",
      "        [ 1.4209],\n",
      "        [ 1.7542],\n",
      "        [ 0.8942]])\n",
      "epoch 5, loss: 0.000048\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "num_epochs = 5\n",
    "for i in range(num_epochs):\n",
    "    for inputs,labels in dataloader:\n",
    "        inputs = inputs.float()\n",
    "        outputs = linear_model(inputs)\n",
    "        labels = labels.float()\n",
    "        print(labels)\n",
    "        print(labels.view(-1,1))\n",
    "        loss = criterion(outputs,labels.view(-1,1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "    print(\"epoch %d, loss: %f\" %(i+1,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[2.4961, 2.9972]], requires_grad=True)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0081], requires_grad=True)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模拟梯度爆炸和弥散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_size = 100\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_size):\n",
    "        super(net,self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(hidden_size,hidden_size,bias = False) for i in range(100)])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for linear in self.linears:\n",
    "            x = linear(x)\n",
    "        return x \n",
    "    \n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight.data,std = np.sqrt(hidden_size) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((16,256))\n",
    "model = net(256)\n",
    "model.initialize()\n",
    "\n",
    "out = model(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单实现softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "input_size = 784 # 28*28\n",
    "out_size = 10 # 10 classes\n",
    "learning_rate = 0.1\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = torchvision.datasets.FashionMNIST(\"input/train\",train=True,download=True,transform=transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST(\"input/test\",train=False,download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,shuffle=True,batch_size=256)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,shuffle=False,batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the net\n",
    "class net(nn.Module):\n",
    "    def __init__(self,input_size,out_size):\n",
    "        super(net,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.out_size = out_size\n",
    "        self.fc = nn.Linear(input_size,out_size,bias=True)\n",
    "    def forward(self,X):\n",
    "        out = X.view(-1,input_size)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Linear):\n",
    "                init.normal_(m.weight.data,mean=0,std=0.01)\n",
    "                init.constant_(m.bias.data, val = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_size,out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net init\n",
    "model.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0034,  0.0021,  0.0015,  ..., -0.0029, -0.0004,  0.0123],\n",
      "        [-0.0127,  0.0049,  0.0074,  ..., -0.0005, -0.0025,  0.0114],\n",
      "        [-0.0012,  0.0088,  0.0120,  ...,  0.0076, -0.0146, -0.0200],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0022, -0.0154,  ...,  0.0014, -0.0040,  0.0034],\n",
      "        [-0.0011, -0.0027,  0.0058,  ...,  0.0093, -0.0009, -0.0037],\n",
      "        [-0.0066,  0.0066, -0.0053,  ..., -0.0147,  0.0143, -0.0083]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and optimzer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimzer = torch.optim.SGD(model.parameters(),lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss为:0.7835202217102051\n",
      "epoch:2, loss为:0.5758370757102966\n",
      "epoch:3, loss为:0.45879819989204407\n",
      "epoch:4, loss为:0.5836923122406006\n",
      "epoch:5, loss为:0.34031832218170166\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs,labels in train_loader:\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.size())\n",
    "        #print(labels.size())  # 应当只具有batch这一个维度 or 和outputsize一样\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        optimzer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "    print(\"epoch:{}, loss为:{}\".format(epoch+1,loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = torchvision.datasets.FashionMNIST(\"input/train/\",train = True,download=True,transform=transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST(\"input/train/\",train = False,download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,shuffle=True,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,shuffle=False,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build network\n",
    "class net(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size,bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,X):\n",
    "        output = X.view(-1,input_size)\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(input_size,hidden_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of net(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
